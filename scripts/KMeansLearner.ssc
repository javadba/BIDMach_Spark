import org.apache.spark.rdd.RDD
import scala.reflect.ClassTag
import BIDMat.MatIO
import BIDMat.SerText
import BIDMach.RunOnSpark._
import BIDMach.Learner
import BIDMach.models.KMeans
import org.apache.spark.HashPartitioner
import java.net.InetAddress

val mnistPath=System.getProperty("bidmach.merged.hdfs.path")
val numExecutors = System.getProperty("spark.executors").toInt
println(s"mnistPath=$mnistPath")
val rddData = sc.sequenceFile(mnistPath, classOf[SerText], classOf[BIDMat.MatIO]).partitionBy(new HashPartitioner(numExecutors)).persist()
val (learner,opts) = KMeans.learner()
opts.batchSize = 10000
opts.npasses = 10
opts.dim = 256
def time[R](block: => R): R = {
    val t0 = System.nanoTime()
    val result = block
    val t1 = System.nanoTime()
    println("Elapsed time: " + (t1 - t0)/math.pow(10, 9)+ "s")
    result
}
val result = time {runOnSpark(sc,learner, rddData, numExecutors)}
